{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rutvi/cs50Lecture0/blob/master/nisarg.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5t_mAQLz-i18"
      },
      "outputs": [],
      "source": [
        "!pip install  transformers\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from transformers import BertTokenizer, TFBertModel\n",
        "from keras.layers import Input, Dense, Bidirectional, GRU, Conv1D, GlobalMaxPooling1D, Dropout, Flatten, Activation, Lambda\n",
        "from keras.models import Model\n",
        "from keras import backend as K\n",
        "from keras.optimizers import Adam\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "# Load BERT tokenizer and model\n",
        "model_name = 'bert-base-uncased'\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "bert_model = TFBertModel.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "UnbawpqS-kKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "dataset = pd.read_csv('/content/drive/MyDrive/M.E. sem4/PrePostQuestions.csv')\n",
        "\n",
        "# Convert dataset to DataFrame\n",
        "df = pd.DataFrame(dataset)"
      ],
      "metadata": {
        "id": "22e1Wt_0-pH8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "DfhycEZ0-uiH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize input text\n",
        "\n",
        "encoded_data  = df['question'].apply(lambda x: tokenizer.encode_plus(x, max_length=128, truncation=True, padding='max_length',\n",
        "                                add_special_tokens=True, return_tensors='tf'))\n"
      ],
      "metadata": {
        "id": "ioqAhbFA-xN9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create TensorFlow dataset from encoded data\n",
        "input_ids = np.array([encoded_data[i]['input_ids'] for i in range(len(encoded_data))]).squeeze()\n",
        "attention_mask = np.array([encoded_data[i]['attention_mask'] for i in range(len(encoded_data))]).squeeze()\n",
        "token_type_ids = np.array([encoded_data[i]['token_type_ids'] for i in range(len(encoded_data))]).squeeze()\n",
        "input_ids = tf.constant(input_ids)\n",
        "attention_mask = tf.constant(attention_mask)\n",
        "token_type_ids = tf.constant(token_type_ids)"
      ],
      "metadata": {
        "id": "Hygl9cKt-2b9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices((input_ids, attention_mask, token_type_ids))"
      ],
      "metadata": {
        "id": "0y_VlM_2-5de"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to convert a batch of inputs to a batch of embeddings\n",
        "@tf.function\n",
        "def generate_embeddings(input_ids, attention_mask, token_type_ids):\n",
        "    embeddings = bert_model([input_ids, attention_mask, token_type_ids])[0]\n",
        "    return embeddings\n"
      ],
      "metadata": {
        "id": "qveRxa5c--vU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate embeddings for each batch\n",
        "batch_size = 4\n",
        "batches = dataset.batch(batch_size)\n",
        "embeddings = []\n",
        "for i,batch in batches:\n",
        "    batch_input_ids, batch_attention_mask, batch_token_type_ids = batch\n",
        "    batch_embeddings = generate_embeddings(batch_input_ids, batch_attention_mask, batch_token_type_ids)\n",
        "    embeddings.append(batch_embeddings)\n",
        "    # Append the embeddings to the output file\n",
        "    if i == 0:\n",
        "        np.save('/content/drive/MyDrive/M.E. sem4/n_embeddings.npy', embeddings.numpy())\n",
        "    else:\n",
        "        with open('n_embeddings.npy', 'ab') as f:\n",
        "            np.save(f, embeddings.numpy())\n",
        "\n",
        "    # Clear the embeddings array to free up RAM\n",
        "    del embeddings\n",
        "    tf.keras.backend.clear_session()\n",
        "\n"
      ],
      "metadata": {
        "id": "p0fsUiJF_CCs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}